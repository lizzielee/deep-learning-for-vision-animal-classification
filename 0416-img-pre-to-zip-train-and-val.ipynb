{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pytorch-pretrained-image-models', 'iwildcam-2019-fgvc6']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Import packages\n",
    "import time, copy\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models.vgg import model_urls\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Class names\n",
    "class_names = ['empty', 'deer', 'moose', 'squirrel', 'rodent', 'small_mammal', 'elk', 'pronghorn_antelope', \n",
    "               'rabbit', 'bighorn_sheep', 'fox', 'coyote', 'black_bear', 'raccoon', 'skunk', 'wolf', \n",
    "               'bobcat', 'cat', 'dog', 'opossum', 'bison', 'mountain_goat', 'mountain_lion']\n",
    "\n",
    "# csv file & data file path\n",
    "train_csv_file = '../input/iwildcam-2019-fgvc6/train.csv'\n",
    "train_data_dir = '../input/iwildcam-2019-fgvc6/train_images'\n",
    "test_csv_file = '../input/iwildcam-2019-fgvc6/test.csv'\n",
    "test_data_dir = '../input/iwildcam-2019-fgvc6/test_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read basic information in csv files and save in pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv\n",
    "train_val_df = pd.read_csv(train_csv_file)\n",
    "test_df = pd.read_csv(test_csv_file)\n",
    "\n",
    "# Create a new feature 'category' (string) in train_df for better plotting/understanding\n",
    "train_val_df['category'] = train_val_df['category_id'].apply(lambda id: class_names[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>date_captured</th>\n",
       "      <th>file_name</th>\n",
       "      <th>frame_num</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>rights_holder</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>seq_num_frames</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>2011-05-13 23:43:18</td>\n",
       "      <td>5998cfa4-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>5998cfa4-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>33</td>\n",
       "      <td>Justin Brown</td>\n",
       "      <td>6f084ccc-5567-11e8-bc84-dca9047ef277</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "      <td>opossum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>2012-03-17 03:48:44</td>\n",
       "      <td>588a679f-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>588a679f-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>115</td>\n",
       "      <td>Justin Brown</td>\n",
       "      <td>6f12067d-5567-11e8-b3c0-dca9047ef277</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "      <td>opossum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-05-11 11:56:46</td>\n",
       "      <td>59279ce3-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>59279ce3-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>96</td>\n",
       "      <td>Erin Boydston</td>\n",
       "      <td>6faa92d1-5567-11e8-b1ae-dca9047ef277</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-06 02:00:00</td>\n",
       "      <td>5a2af4ab-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>5a2af4ab-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>57</td>\n",
       "      <td>Erin Boydston</td>\n",
       "      <td>6f7d4702-5567-11e8-9e03-dca9047ef277</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-12 13:11:16</td>\n",
       "      <td>599fbd89-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>599fbd89-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>46</td>\n",
       "      <td>Justin Brown</td>\n",
       "      <td>6f1728a1-5567-11e8-9be7-dca9047ef277</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id        date_captured    ...    height  category\n",
       "0           19  2011-05-13 23:43:18    ...       747   opossum\n",
       "1           19  2012-03-17 03:48:44    ...       747   opossum\n",
       "2            0  2014-05-11 11:56:46    ...       747     empty\n",
       "3            0  2013-10-06 02:00:00    ...       747     empty\n",
       "4            0  2011-07-12 13:11:16    ...       747     empty\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Arrange the dataset in pytorch ImageFolder way\n",
    "class IWildCamDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pandas.DataFrame): Contains basic information.\n",
    "            root_dir (string): The path where image data is saved.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir,\n",
    "                                self.df.iloc[idx].file_name)\n",
    "        with open(img_path, 'rb') as f:\n",
    "            image = Image.open(f)\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        if('category_id' in self.df.iloc[idx]):\n",
    "            category = self.df.iloc[idx].category_id\n",
    "        else:\n",
    "            # In test set, there is no given category. Here we will not return the category,\n",
    "            # return the img_id instead. (Because we need to keep track of the img id during\n",
    "            # testing)\n",
    "            category = self.df.iloc[idx].id\n",
    "        \n",
    "        if('file_name' in self.df.iloc[idx]):\n",
    "            filename = self.df.iloc[idx].file_name\n",
    "\n",
    "        # Transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, category, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a subset of train dataset: should be comment after tuning the model\n",
    "train_val_df = train_val_df.sample(20000, random_state=199)\n",
    "\n",
    "# Split into train_df and val_df\n",
    "train_df = train_val_df.sample(frac=0.8, random_state=201)\n",
    "val_df = train_val_df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('train_df.pkl')\n",
    "val_df.to_pickle('val_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Data transforms\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(128),  # 1. Resize smallest side to 128.\n",
    "     transforms.CenterCrop(128), # 2. Crop the center 128x128 pixels.\n",
    "     transforms.ToTensor(), # 3. Convert to pytorch tensor.\n",
    "     transforms.Normalize(mean = [0.485, 0.456, 0.406],  # normalize.\n",
    "                          std = [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Get dataset\n",
    "train_set = IWildCamDataset(train_df, train_data_dir, transform=data_transforms)\n",
    "val_set   = IWildCamDataset(val_df, train_data_dir, transform=data_transforms)\n",
    "test_set  = IWildCamDataset(test_df, test_data_dir, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0a/50a827d13a75754a8500fa854517f09886027005b09ac5210dca9f0aa101/opencv_contrib_python-4.1.0.25-cp36-cp36m-manylinux1_x86_64.whl (32.6MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 32.6MB 1.2MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.6/site-packages (from opencv-contrib-python) (1.16.3)\r\n",
      "Installing collected packages: opencv-contrib-python\r\n",
      "Successfully installed opencv-contrib-python-4.1.0.25\r\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n",
      "['pytorch-pretrained-image-models', 'iwildcam-2019-fgvc6']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "!pip install opencv-contrib-python\n",
    "import cv2\n",
    "print(os.listdir(\"../input\"))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.misc\n",
    "import zipfile\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic White Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = cv2.xphoto.createSimpleWB()\n",
    "wb.setP(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  __output__.json  train_df.pkl  val_df.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-processing for train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/opt/conda/lib/python3.6/zipfile.py:1355: UserWarning: Duplicate name: '599d7e8c-23d2-11e8-a6a3-ec086b02610b.jpg'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "/opt/conda/lib/python3.6/zipfile.py:1355: UserWarning: Duplicate name: '5858c11b-23d2-11e8-a6a3-ec086b02610b.jpg'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n"
     ]
    }
   ],
   "source": [
    "startdir = \"p_train_set\"  #要压缩的文件夹路径\n",
    "file_news = startdir +'.zip' # 压缩后文件夹的名字\n",
    "azip = zipfile.ZipFile(file_news, 'w')\n",
    "root_dir = '../input/iwildcam-2019-fgvc6/train_images/'\n",
    "desired_size = 256\n",
    "#fig=plt.figure(figsize=(32, 128))\n",
    "#train_list = []\n",
    "\n",
    "for idx in range(0, len(train_set)):\n",
    "    train_img = root_dir + train_set[idx][2]\n",
    "    temp_img = cv2.imread(train_img, cv2.IMREAD_COLOR)        \n",
    "    \n",
    "    img_wb = wb.balanceWhite(temp_img)\n",
    "\n",
    "    img_lab = cv2.cvtColor(img_wb, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "    l, a, b = cv2.split(img_lab)\n",
    "    res_l = clahe.apply(l)\n",
    "    res = cv2.merge((res_l, a, b))\n",
    "\n",
    "    res = cv2.cvtColor(res, cv2.COLOR_Lab2BGR)\n",
    "    resized = cv2.resize(res, (desired_size,)*2).astype('uint8')\n",
    "    \n",
    "    imgname = train_set[idx][2]\n",
    "    scipy.misc.imsave(imgname, resized)\n",
    "    azip.write(imgname, compress_type=zipfile.ZIP_LZMA)\n",
    "    #train_list.append(imgname)\n",
    "    #for filename in os.listdir('/kaggle/working'):\n",
    "        #if filename.endswith('.jpg'):\n",
    "    os.remove(imgname)\n",
    "\n",
    "#p_train_set = zip(train_list)\n",
    "azip.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-processing for val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2304x9216 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "startdir = \"p_val_set\"  #要压缩的文件夹路径\n",
    "file_news = startdir +'.zip' # 压缩后文件夹的名字\n",
    "azip = zipfile.ZipFile(file_news, 'w')\n",
    "root_dir = '../input/iwildcam-2019-fgvc6/train_images/'\n",
    "fig=plt.figure(figsize=(32, 128))\n",
    "#train_list = []\n",
    "\n",
    "for idx in range(0, len(val_set)):\n",
    "    val_img = root_dir + val_set[idx][2]\n",
    "    temp_img = cv2.imread(val_img, cv2.IMREAD_COLOR)        \n",
    "    \n",
    "    img_wb = wb.balanceWhite(temp_img)\n",
    "\n",
    "    img_lab = cv2.cvtColor(img_wb, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "    l, a, b = cv2.split(img_lab)\n",
    "    res_l = clahe.apply(l)\n",
    "    res = cv2.merge((res_l, a, b))\n",
    "\n",
    "    res = cv2.cvtColor(res, cv2.COLOR_Lab2BGR)\n",
    "    resized = cv2.resize(res, (desired_size,)*2).astype('uint8')\n",
    "    \n",
    "    imgname = val_set[idx][2]\n",
    "    scipy.misc.imsave(imgname, resized)\n",
    "    azip.write(imgname, compress_type=zipfile.ZIP_LZMA)\n",
    "    #train_list.append(imgname)\n",
    "    os.remove(imgname)\n",
    "\n",
    "#p_train_set = zip(train_list)\n",
    "azip.close()\n",
    "#for filename in os.listdir('/kaggle/working'):\n",
    " #   if filename.endswith('.jpg'):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-processing for test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get a subset of train_val_df and split into train_df & val_df\n",
    "When tuning the model, we will not use the whole train dataset because the dataset is too large. After getting the best model structure, we should comment the code in this section since we should use the complete train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Explore the train set: train_df and val_df\n",
    "We need to make sure that all the 14 classes is contained in train_df and val_df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Get Dataset in pytorch\n",
    "We will use pd.DataFrame (train_df, val_df, test_df) to build torch.utils.data.Dataset (train_set, val_set, test_set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize a few images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load a pretrained model and reset final fully connected layer\n",
    "Here we used the DenseNet 201. The pretrained model weights are loaded from Kaggle dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train the model we defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the result in validation set\n",
    "Confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Show misclassified images\n",
    "We want to explore which type of images are mostly being misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission: using trained model to get predicted classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
